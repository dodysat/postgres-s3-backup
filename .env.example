# PostgreSQL S3 Backup Configuration
# Copy this file to .env and customize the values for your environment

# =============================================================================
# REQUIRED CONFIGURATION
# =============================================================================

# S3 Bucket Configuration
S3_BUCKET=my-backup-bucket
S3_ACCESS_KEY=your-access-key-here
S3_SECRET_KEY=your-secret-key-here

# PostgreSQL Connection
# Format: postgresql://username:password@host:port/database
# Examples:
#   postgresql://user:pass@localhost:5432/mydb
#   postgresql://user:pass@postgres-server:5432/production_db
POSTGRES_CONNECTION_STRING=postgresql://username:password@host:port/database

# Backup Schedule (cron format: minute hour day month day-of-week)
# Examples:
#   0 2 * * *     - Daily at 2:00 AM
#   0 */6 * * *   - Every 6 hours
#   0 2 * * 0     - Weekly on Sunday at 2:00 AM
#   0 2 1 * *     - Monthly on the 1st at 2:00 AM
BACKUP_INTERVAL=0 2 * * *

# =============================================================================
# OPTIONAL CONFIGURATION
# =============================================================================

# S3 Endpoint URL (for custom S3-compatible services like MinIO)
# Leave commented for AWS S3, uncomment and modify for other services
# S3_URL=https://s3.amazonaws.com
# S3_URL=https://minio.example.com

# S3 Path Prefix (organizes backups within the bucket)
# This will be prepended to all backup file names
S3_PATH=postgres-backups

# Backup Retention Period (in days)
# Backups older than this will be automatically deleted
# Leave commented or set to 0 to keep all backups
BACKUP_RETENTION_DAYS=30

# Logging Level
# Options: error, warn, info, debug
LOG_LEVEL=info

# Timezone (optional)
# Set the container timezone for accurate scheduling
# TZ=UTC
# TZ=America/New_York
# TZ=Europe/London

# =============================================================================
# DOCKER COMPOSE CUSTOMIZATION EXAMPLES
# =============================================================================

# Example 1: Multiple Database Backups
# You can run multiple instances by creating separate compose files:
# docker-compose -f docker-compose.yml -f docker-compose.db1.yml up -d
# docker-compose -f docker-compose.yml -f docker-compose.db2.yml up -d

# Example 2: Custom Resource Limits
# Modify the deploy.resources section in docker-compose.yml based on:
# - Database size
# - Available system resources
# - Backup frequency

# Example 3: Network Isolation
# Uncomment the networks section in docker-compose.yml if you want to:
# - Isolate backup traffic
# - Connect to specific database networks
# - Implement custom networking policies

# =============================================================================
# SECURITY NOTES
# =============================================================================

# 1. Never commit .env files with real credentials to version control
# 2. Use Docker secrets for production deployments
# 3. Ensure S3 credentials have minimal required permissions:
#    - s3:PutObject (for uploads)
#    - s3:ListBucket (for retention management)
#    - s3:DeleteObject (for retention cleanup)
# 4. Use read-only PostgreSQL credentials when possible
# 5. Consider using IAM roles instead of access keys in AWS environments